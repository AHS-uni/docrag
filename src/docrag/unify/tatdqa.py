import json
from pathlib import Path

from docrag.schema import (
    Answer,
    AnswerFormat,
    AnswerType,
    Document,
    DocumentType,
    Evidence,
    EvidenceSource,
    Question,
    QuestionType,
    UnifiedEntry,
)
from docrag.schema.raw import TATDQARawEntry
from docrag.schema.utils import tag_inferred, tag_low_quality, tag_missing

from .unifier import Unifier, register_unifier
from .exceptions import UnificationError

__all__ = ["TATDQAUnifier"]


@register_unifier("tatdqa")
class TATDQAUnifier(Unifier[TATDQARawEntry]):

    def _discover_raw_qas(self) -> list[Path]:
        # All raw TAT-DQA splits are plain JSON files under raw_qas_directory/
        return sorted(self.raw_qas_directory.glob("*.json"))

    def _load_raw_qas(self, path: Path) -> list[TATDQARawEntry]:
        # Entries are in a top level array
        payload = json.loads(path.read_text(encoding="utf-8"))
        return [TATDQARawEntry.model_validate(item) for item in payload]

    def _build_entry(
        self,
        raw: TATDQARawEntry,
        document: Document,
        question: Question,
        evidence: Evidence,
        answer: Answer,
    ) -> UnifiedEntry:
        entry = UnifiedEntry(
            id=f"{raw.doc_uid}-{raw.question_uid}",
            document=document,
            question=question,
            evidence=evidence,
            answer=answer,
        )
        return entry

    def _build_document(self, raw: TATDQARawEntry) -> Document | None:
        corpus_pages = self._corpus_documents.get(raw.doc_uid, [])

        if len(corpus_pages) == 0:
            # Document not found in corpus
            if self.test_mode:
                self.logger.warning("Document missing in corpus: doc_uid=%s", raw.doc_uid)
                self._problematic["documents"].append(
                    {"document_id": raw.doc_uid, "reason": "Missing in corpus."}
                )
                return None
            else:
                raise UnificationError(f"Document '{raw.doc_uid}' not found in corpus.")

        document = Document(
            id=raw.doc_uid,
            count_pages=len(corpus_pages),
        )
        document.type = DocumentType.FINANCIAL
        document.tags.append(
            tag_inferred("type", "All TAT-DQA documents are financial reports.")
        )
        return document

    def _build_question(self, raw: TATDQARawEntry) -> Question:
        question = Question(id=raw.question_uid, text=raw.question)
        question.type = self._map_question_type(raw.answer_type)
        question.tags.append(
            tag_low_quality("type", "Question type  classification in TATDQA is limited. Only provides four broad categories.")
        )
        return question

    def _build_evidence(self, raw: TATDQARawEntry) -> Evidence:
        evidence = Evidence()
        page_idx = raw.doc_page - 1

        if (raw.doc_uid, page_idx) not in self._corpus_index:
            if self.test_mode:
                evidence.pages = [0]
                self.logger.warning(
                    "doc_page %s for doc_uid=%s not found in corpus; defaulting to page 0",
                    page_idx, raw.doc_uid
                )
                self._problematic["questions"].append({
                    "question_uid": raw.question_uid,
                    "reason": "doc_page not found in corpus"
                })
            else:
                raise UnificationError(
                    f"doc_page {page_idx} not in corpus for doc_uid={raw.doc_uid}, "
                    f"question_uid={raw.question_uid}"
                )


        evidence.pages = [page_idx]
        evidence.tags.append(tag_missing("sources", "TATDQA does not provide evidence sources."))

        return evidence

    def _build_answer(self, raw: TATDQARawEntry) -> Answer:
        answer = Answer()

        if not raw.answer:
            if self.test_mode:
                self.logger.warning("Missing answer for question_id=%s.", raw.question_uid)
                self._problematic["questions"].append({
                    "question_id": raw.question_uid,
                    "reason": "Missing answer.",
                })
                return answer
            else:
                raise UnificationError(f"answer is empty or None for question_id={raw.question_uid}")

        if isinstance(raw.answer, list):
            if len(raw.answer) > 1:
                combined = self._handle_list_answers(raw.answer)
                answer.variants = [combined]
                answer.format = AnswerFormat.LIST
            else:
                single = raw.answer[0]
                answer.variants = [str(single)]
                answer.format = self._infer_answer_format(single)
        else:
            answer.variants = [str(raw.answer)]
            answer.format = self._infer_answer_format(raw.answer)

        if raw.derivation:
            answer.rationale = raw.derivation
        else:
            answer.tags.append(tag_missing("rationale", "Rationale not provided for this answer."))

        answer.type = AnswerType.ANSWERABLE
        answer.tags.append(tag_inferred("format", "Answer format has been inferred based on it's data type."))
        return answer

    def _infer_answer_format(self, answer:  str | int | float) -> AnswerFormat:
        """
        Infer the answer format by checking the type of the answer field.
        """
        if isinstance(answer, int):
            return AnswerFormat.INTEGER
        if isinstance(answer, float):
            return AnswerFormat.FLOAT
        return AnswerFormat.STRING

    def _map_question_type(self, answer_type: str) -> QuestionType:
        """
        Map the raw answer_type string to our QuestionType enum.
        """
        mapping: dict[str, QuestionType] = {
            "span": QuestionType.EXTRACTIVE,
            "multi-span": QuestionType.EXTRACTIVE,
            "arithmetic": QuestionType.ARITHMETIC,
            "count": QuestionType.COUNTING,
        }
        return mapping.get(answer_type, QuestionType.OTHER)

    def _map_evidence_source(self, answer_type: str) -> EvidenceSource:
        """
        Map the raw answer_type string to our EvidenceSource enum.
        """
        mapping: dict[str, EvidenceSource] = {
            "span": EvidenceSource.SPAN,
            "multi-span": EvidenceSource.SPAN,
        }
        return mapping.get(answer_type, EvidenceSource.OTHER)

    def _handle_list_answers(self, answers: list[str]) -> str:
        """
        Convert a list of answer items into a single string representation,
        e.g. ["foo", "bar"] â†’ "['foo', 'bar']".
        """
        item_strings = [f"'{item}'" for item in answers]
        return "[" + ", ".join(item_strings) + "]"
